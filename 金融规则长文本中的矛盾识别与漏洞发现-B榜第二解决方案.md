# 金融规则长文本中的矛盾识别与漏洞发现-B榜第二解决方案

## 目录

1. ### 方案综述

2. ### 代码运行

3. ### 方案细节描述

4. ### 提升空间

### 方案综述

我们的方案经历了以下迭代过程：

- 单一LLM、同一套prompt模板、few-shot提示
- 单一LLM、按照错误类型区分prompt、zero-shot提示
- 文本前处理、关键词筛选机制、单一LLM、按照错误类型区分prompt、zero-shot提示
- 文本前处理、关键词筛选机制、双LLM互补、按照错误类型区分prompt、zero-shot提示
- 文本前处理、关键词筛选机制、双LLM互补、按照错误类型区分prompt、按照错误类型设计few-shot和zero-shot提示、筛选结果后处理

> 值得说明的是，我们考虑了微调方案，但是公开数据集不能很好地cover本次赛题中招标书、研报、法律、保险合同四种类型的文本，担心微调出现过拟合问题，因此选择直接使用开源模型进行矛盾识别。
>
> 本次方案选择了**通义金融-14B-Chat-Int4**（TongyiFinance/Tongyi-Finance-14B-Chat-Int4）、**glm-4-9b-chat**（ZhipuAI/glm-4-9b-chat）两款大模型，利用前者基于金融领域语料进行微调的特点，执行金融知识理解任务；利用后者逻辑推理能力、指令跟随能力强的特点，执行错误识别和结构化输出任务。

方案流程图如下所示：

![flowchart](.\fig\flowchart.png)

### 代码运行

***🙇‍♂️🙇‍♂️由于作者是一个tmux菜鸟，没能实现一键启动服务和创建新窗口执行脚本，所以辛苦组委会手动运行每个部分，非常感谢！***

- **部署Qwen和GLM**

```bash
sh download_model.sh
```

> 注：依赖于魔搭，请确保已安装魔搭。
>
> 安装路径为/hy-tmp/model_cache/，如果您需要更改它，请修改以下四个文件中的路径地址。
>
> GLM9B.py、Qwen14B.py、start_qwen_api_server.sh、start_glm_api_server.sh

- **启动vLLM框架下的Qwen服务**

```bash
sh start_qwen_api_server.sh
```

> 注：如果配置了虚拟环境，请确保在此之前激活了它。依赖于vLLM，请确保已安装vLLM。
>
> 启动成功的标志是：
>
> ![qwen](.\fig\QWEN.png)

- **执行pre脚本**

```bash
sh run_pre.sh
```

> 注：请切换到另一个终端页面执行（我们需要维持Qwen服务），这一执行过程耗时约15min（您可以切出页面稍作等待🍵）。
>
> 如果配置了虚拟环境，请确保在此之前激活了它。
>
> 开始运行的标志是（我们可以看到模型已经在处理文档）：
>
> ![pre](.\fig\pre.png)

- **关闭Qwen服务以释放显存，我们要切换到跟随指令能力更好的GLM来完成后续步骤**

> 在第一个终端键入Ctrl+C即可

- **启动vLLM框架下的GLM服务**

```bash
sh start_glm_api_server.sh
```

> 启动成功的标志是（与上一个服务端口号不同😀😀😀）：
>
> ![glm](.\fig\GLM.png)

- **执行main脚本**

```bash
sh run_main.sh
```

> 开始运行的标志依然是模型开始处理文档，这一执行过程耗时约30min（您可以切出页面稍作等待🍵）。

- **推理结束**

> 推理结束后我们就得到了结果json文件
>
> ![output](.\fig\output.png)

### 方案细节描述


### 提升空间
- 1）方法优势：  
本方法通过高效数据预处理，采用pysbd和模式识别技术进行分句和初步筛选，提升了数据输入的准确性，提高了模型性能。  
本方法采用双模型架构，通义金融14B模型结合GLM-4-9B-chat模型，利用其在金融领域的特化训练，提升了矛盾和漏洞识别的精度。  
本方法采用本地高效部署，通过vllm框架进行本地部署，有效提高资源利用率，降低延迟，提升模型的整体性能。  
本方法使用针对性错误识别，针对不同类型的错误设计特定的prompt，减轻大语言模型出现的幻觉现象，增强识别效果。  
本方法在双模型架构的基础上使用了后处理编辑方法，进一步精细化识别和筛选，确保识别结果的准确性和可靠性。  
- 2）限制与不足：  
模型规模和资源需求，大型预训练模型如通义金融14B和GLM-4-9B-chat对计算资源要求较高，增加了部署和运行成本。  
自动化验证和人工介入，完全依赖自动化识别和验证在某些情况下可能不足，需要设计人机协同机制以确保识别结果的准确性。  
- 3）展望与优化  
进一步优化模型的资源使用，采用并行计算技术，提高大模型的运行效率，降低部署成本。  
引入更多的细粒度错误识别技术，如层级分类和多任务学习，提升模型对复杂错误类型的识别能力。  
开发更好的解释机制，如注意力可视化和决策树后处理，增强模型输出的透明性和可解释性。  
将技术方案推广至其他需要长文本错误识别的领域，如法律、医疗、咨询等，扩展应用场景，提高技术的实用价值。  
- 4）方法总结  
本方案提出了使用pysbd以及模式识别匹配进行分句，初步筛选问题段落，精细化数据输入，提高模型精度；并选用通义金融14B模型和GLM-4-9B-chat模型作为基础模型，使用vllm框架提高资源利用率，优化模型性能与识别精度；创新性的设计prompt引导模型识别错误类型实现金融文本错误识别的后处理，实现针对金融文本自动化识别与验证，理解并筛选矛盾与漏洞再识别问题句子。  
尽管目前的金融文本错误识别方法展示了显著的优势，如高效的数据预处理、双模型架构带来的识别精度提升、本地高效部署的资源利用率提升、针对性错误识别和精细化的后处理逻辑， 这些特点都显著提高了模型的性能和准确性，但仍存在一些需要改进的地方。首先，数据集的多样性不足可能限制了模型的泛化能力，未来可以扩展和增强数据集，涵盖更多样化的金融文本类型和错误场景。此外，模型规模大和资源需求高的问题增加了部署和运行成本，需要进一步优化资源使用，采用并行计算技术提高大模型的运行效率。尽管设计了特定的prompt，但在处理复杂错误类型时，模型仍可能出现误识别或漏识别现象，因此，引入更细粒度的错误识别技术，如层级分类和多任务学习，可以提升模型对复杂错误类型的识别能力。完全依赖自动化识别和验证可能不足，设计人机协同验证机制，通过专家反馈和人工标注，提高识别结果的准确性和可靠性是一个有效的改进方向。复杂的大语言模型在决策过程中可能缺乏透明性，需要开发更好的解释机制，如注意力可视化和决策树后处理，以增强模型输出的透明性和可解释性。  
未来可以将本技术方案推广至其他需要长文本错误识别的领域，如法律、医疗、咨询等，扩展应用场景，提高技术的实用价值。今后的算法设计思路将集中在优化资源使用、增强数据多样性、引入细粒度识别技术、设计人机协同机制以及提升模型可解释性，旨在构建一个更加精准、高效且具备广泛应用前景的金融文本错误识别系统。  

